import streamlit as st
import vertexai
from vertexai.language_models import ChatModel, InputOutputTextPair

def main():
    """
    Streamlitã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®ãƒ¡ã‚¤ãƒ³å‡¦ç†ã‚’è¡Œã†é–¢æ•°
    """
    st.title('ã‚·ãƒ³ãƒ—ãƒ«ãªStreamlitã‚¢ãƒ—ãƒª')

    import os

    PROJECT_ID = "linen-option-411401"
    LOCATION = "us-central1"
    MODEL_NAME = "gemini-1.0-pro" 

    try:
        # ç’°å¢ƒå¤‰æ•°ã‹ã‚‰ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆIDã‚’å–å¾—ã—ã‚ˆã†ã¨è©¦ã¿ã‚‹ï¼ˆãƒ‡ãƒ—ãƒ­ã‚¤ç’°å¢ƒå‘ã‘ï¼‰
        project_id_env = os.environ.get("GOOGLE_CLOUD_PROJECT")
        if project_id_env:
            PROJECT_ID = project_id_env

        if not PROJECT_ID or PROJECT_ID == "your-gcp-project-id":
            st.error("GCPãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆIDãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ã‚³ãƒ¼ãƒ‰å†…ã® PROJECT_ID ã‚’è¨­å®šã™ã‚‹ã‹ã€ç’°å¢ƒå¤‰æ•° GOOGLE_CLOUD_PROJECT ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")
            st.stop()

        vertexai.init(project=PROJECT_ID, location=LOCATION)
        st.info(f"Vertex AI SDK initialized. Project: {PROJECT_ID}, Location: {LOCATION}")

    except Exception as e:
        st.error(f"Vertex AI ã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        st.info("èªè¨¼æƒ…å ±ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒã§ã¯ 'gcloud auth application-default login' ã‚’å®Ÿè¡Œã—ã¾ã—ãŸã‹ï¼Ÿ")
        st.stop()

    # --- Streamlit ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ ---
    st.title("ğŸ’¬ Vertex AI ãƒãƒ£ãƒƒãƒˆã‚¢ãƒ—ãƒª")
    st.caption(f"Powered by Google Vertex AI ({MODEL_NAME})")

    # --- ãƒãƒ£ãƒƒãƒˆã‚»ãƒƒã‚·ãƒ§ãƒ³ã®åˆæœŸåŒ– ---
    # st.session_stateã‚’ä½¿ã£ã¦ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã¨Vertex AIã®ãƒãƒ£ãƒƒãƒˆã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’ç®¡ç†
    if "messages" not in st.session_state:
        st.session_state.messages = [] # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’æ ¼ç´ã™ã‚‹ãƒªã‚¹ãƒˆ
    if "chat_session" not in st.session_state:
        try:
            # ãƒãƒ£ãƒƒãƒˆãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰
            chat_model = ChatModel.from_pretrained(MODEL_NAME)
            # ãƒãƒ£ãƒƒãƒˆã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’é–‹å§‹
            # context: å¿…è¦ã§ã‚ã‚Œã°ã€AIã«å‰æçŸ¥è­˜ã‚’ä¸ãˆã‚‹ãŸã‚ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’è¨­å®š
            # examples: Few-shotãƒ—ãƒ­ãƒ³ãƒ—ãƒ†ã‚£ãƒ³ã‚°ã®ãŸã‚ã®ä¾‹ã‚’è¨­å®š
            st.session_state.chat_session = chat_model.start_chat(
                context="ã‚ãªãŸã¯è¦ªåˆ‡ã§å½¹ç«‹ã¤AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚",
                # examples=[
                #     InputOutputTextPair(
                #         input_text="ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã®å…¥åŠ›ä¾‹",
                #         output_text="æœŸå¾…ã™ã‚‹AIã®å¿œç­”ä¾‹",
                #     ),
                # ]
            )
        except Exception as e:
            st.error(f"ãƒãƒ£ãƒƒãƒˆãƒ¢ãƒ‡ãƒ« ({MODEL_NAME}) ã®ãƒ­ãƒ¼ãƒ‰ã¾ãŸã¯ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®é–‹å§‹ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
            st.stop()

    # --- ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®è¡¨ç¤º ---
    # st.session_state.messages ã«ä¿å­˜ã•ã‚Œã¦ã„ã‚‹å±¥æ­´ã‚’è¡¨ç¤º
    for message in st.session_state.messages:
        # "role" (user or model) ã«åŸºã¥ã„ã¦è¡¨ç¤ºã‚’åˆ†ã‘ã‚‹
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    # --- ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã®å‡¦ç† ---
    # st.chat_inputã§ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã®å…¥åŠ›ã‚’å—ã‘ä»˜ã‘ã‚‹
    if prompt := st.chat_input("ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„..."):
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å±¥æ­´ã«è¿½åŠ ã—ã€è¡¨ç¤º
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        # --- Vertex AI ã¸ã®å•ã„åˆã‚ã›ã¨å¿œç­”å‡¦ç† ---
        try:
            # Vertex AIã®ãƒãƒ£ãƒƒãƒˆã‚»ãƒƒã‚·ãƒ§ãƒ³ã«ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’é€ä¿¡
            chat = st.session_state.chat_session
            # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§å¿œç­”ã‚’åˆ¶å¾¡ã™ã‚‹ã“ã¨ã‚‚å¯èƒ½
            # parameters = {
            #     "temperature": 0.2,       # å¿œç­”ã®ãƒ©ãƒ³ãƒ€ãƒ æ€§ (0ã«è¿‘ã„ã»ã©æ±ºå®šçš„)
            #     "max_output_tokens": 256, # æœ€å¤§å‡ºåŠ›ãƒˆãƒ¼ã‚¯ãƒ³æ•°
            #     "top_p": 0.8,             # Top-pã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
            #     "top_k": 40,              # Top-kã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
            # }
            # response = chat.send_message(prompt, **parameters)
            response = chat.send_message(prompt)
            response_text = response.text

            # AIã®å¿œç­”ã‚’å±¥æ­´ã«è¿½åŠ ã—ã€è¡¨ç¤º
            st.session_state.messages.append({"role": "model", "content": response_text})
            with st.chat_message("assistant"): # Streamlitã§ã¯AIã®å½¹å‰²ã¯"assistant"ãŒä¸€èˆ¬çš„
                st.markdown(response_text)

        except Exception as e:
            st.error(f"Vertex AI ã¸ã®å•ã„åˆã‚ã›ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            st.warning("ã‚‚ã†ä¸€åº¦è©¦ã™ã‹ã€å°‘ã—å¾…ã£ã¦ã‹ã‚‰å†åº¦å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")


if __name__ == "__main__":
    main()