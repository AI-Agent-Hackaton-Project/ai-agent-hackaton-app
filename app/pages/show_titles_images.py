import streamlit as st
import os
from dotenv import load_dotenv
import vertexai
import base64
from io import BytesIO

from langchain_google_vertexai import ChatVertexAI
from langchain.prompts import PromptTemplate
from langchain_core.messages import HumanMessage

from vertexai.preview.vision_models import ImageGenerationModel
from typing import Optional
import traceback

try:
    from utils.generate_titles import generate_titles_for_prefecture
    from config.constants import JAPAN_PREFECTURES
except ImportError as e:
    st.error(f"å¿…é ˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
    st.error(
        "utils.generate_titlesã¨config.constantsãƒ•ã‚¡ã‚¤ãƒ«ãŒãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã«å«ã¾ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚"
    )
    st.stop()

load_dotenv()
GCP_PROJECT_ID = os.getenv("GCP_PROJECT_ID")
GCP_LOCATION = os.getenv("GCP_LOCATION")

if not GCP_PROJECT_ID or not GCP_LOCATION:
    st.error("GCP_PROJECT_IDã¾ãŸã¯GCP_LOCATIONç’°å¢ƒå¤‰æ•°ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
    st.stop()

IMAGE_PROMPT_TEMPLATE = PromptTemplate(
    input_variables=[
        "prefecture",
        "main_title",
        "sub_title",
        "regional_characteristics",
    ],
    template="""
ä»¥ä¸‹ã®æƒ…å ±ã‚’åŸºã«ã€ç”»åƒç”ŸæˆAIç”¨ã®è©³ç´°ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

åœ°åŸŸ: {prefecture}
ãƒ¡ã‚¤ãƒ³ãƒ†ãƒ¼ãƒ: {main_title}
ã‚µãƒ–ãƒ†ãƒ¼ãƒ: {sub_title}
åœ°åŸŸç‰¹æ€§: {regional_characteristics}

è¦æ±‚:
1. {prefecture}ã®ç‰¹å¾´çš„ãªé¢¨æ™¯ã‚„å»ºç‰©ã€æ–‡åŒ–ã‚’å«ã‚ã‚‹
2. {main_title}ã¨{sub_title}ã®ãƒ†ãƒ¼ãƒã‚’è¦–è¦šçš„ã«è¡¨ç¾ã™ã‚‹
3. æ—¥æœ¬ã®ã‚¢ãƒ‹ãƒ¡é¢¨ã®ç¾ã—ã„èƒŒæ™¯ç”»ã¨ã—ã¦æã
4. 4:3ã®ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”ã§åˆ¶ä½œ
5. æ–‡å­—ã‚„ãƒ†ã‚­ã‚¹ãƒˆã¯ä¸€åˆ‡å«ã‚ãªã„

å‡ºåŠ›ã¯ç”»åƒç”ŸæˆAIã«ç›´æ¥å…¥åŠ›ã§ãã‚‹å½¢å¼ã®è‹±èªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§è¨˜è¿°ã—ã¦ãã ã•ã„ã€‚
""",
)


@st.cache_resource
def initialize_vertex_ai():
    """Vertex AIåˆæœŸåŒ–"""
    try:
        st.info(
            f"Vertex AIåˆæœŸåŒ–ä¸­... ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ: {GCP_PROJECT_ID}, å ´æ‰€: {GCP_LOCATION}"
        )
        vertexai.init(project=GCP_PROJECT_ID, location=GCP_LOCATION)
        image_model = ImageGenerationModel.from_pretrained(
            "imagen-3.0-fast-generate-001"
        )
        llm = ChatVertexAI(
            model_name="gemini-2.0-flash-lite-001",
            project=GCP_PROJECT_ID,
            location=GCP_LOCATION,
            temperature=0.7,
        )
        st.success("Vertex AIã¨LLMã®åˆæœŸåŒ–ã«æˆåŠŸã—ã¾ã—ãŸ!")
        return image_model, llm
    except Exception as e:
        st.error(f"Vertex AIåˆæœŸåŒ–å¤±æ•—: {e}")
        st.code(traceback.format_exc())
        return None, None


@st.cache_data(show_spinner=False)
def generate_regional_characteristics(_llm: ChatVertexAI, prefecture: str) -> str:
    """æŒ‡å®šã•ã‚ŒãŸéƒ½é“åºœçœŒã®åœ°åŸŸç‰¹æ€§ã‚’AIã§ç”Ÿæˆ"""
    prompt = f"""
{prefecture}ã®ä»£è¡¨çš„ãªç‰¹å¾´ã‚’æ•™ãˆã¦ãã ã•ã„ã€‚ä»¥ä¸‹ã®è¦ç´ ã‚’å«ã‚ã¦150æ–‡å­—ç¨‹åº¦ã§è¨˜è¿°ã—ã¦ãã ã•ã„ï¼š

1. æœ‰åãªè¦³å…‰åœ°ã‚„ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯
2. è‡ªç„¶ç’°å¢ƒã®ç‰¹å¾´
3. æ–‡åŒ–çš„ãªç‰¹è‰²
4. ç‰¹ç”£å“ã‚„åç‰©

ä¾‹ï¼šæ²–ç¸„çœŒã®å ´åˆ
ç¾ã—ã„æµ·ã¨ã‚µãƒ³ã‚´ç¤ã€é¦–é‡ŒåŸãªã©ã®ç‰çƒæ–‡åŒ–ãŒè‰²æ¿ƒã„æ²–ç¸„çœŒã€‚

ãƒ»è¦³å…‰åœ°ãƒ»ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯: ç¾ã‚‰æµ·æ°´æ—é¤¨ã€é¦–é‡ŒåŸã€å›½éš›é€šã‚Š
ãƒ»è‡ªç„¶ç’°å¢ƒ: ã‚¨ãƒ¡ãƒ©ãƒ«ãƒ‰ã‚°ãƒªãƒ¼ãƒ³ã®æµ·ã€äºœç†±å¸¯æ°—å€™ã€å¤šæ§˜ãªå‹•æ¤ç‰©
ãƒ»æ–‡åŒ–: ç‰çƒæ–‡åŒ–ã€ã‚¨ã‚¤ã‚µãƒ¼ã€ä¸‰ç·š
ãƒ»ç‰¹ç”£å“ãƒ»åç‰©: æµ·ã¶ã©ã†ã€ã‚´ãƒ¼ãƒ¤ãƒãƒ£ãƒ³ãƒ—ãƒ«ãƒ¼ã€æ³¡ç››

{prefecture}ã«ã¤ã„ã¦åŒæ§˜ã®å½¢å¼ã§å›ç­”ã—ã¦ãã ã•ã„ã€‚
"""
    try:
        with st.spinner(f"{prefecture}ã®åœ°åŸŸç‰¹æ€§ã‚’ç”Ÿæˆä¸­..."):
            response = _llm.invoke([HumanMessage(content=prompt)])
            result = response.content.strip()
            return result if result else f"{prefecture}ã®ç¾ã—ã„è‡ªç„¶ã¨æ–‡åŒ–çš„ç‰¹å¾´"
    except Exception as e:
        st.warning(f"åœ°åŸŸç‰¹æ€§ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
        return f"{prefecture}ã®ç¾ã—ã„è‡ªç„¶ã¨ä¼çµ±çš„ãªæ–‡åŒ–"


def generate_image_prompt(
    llm: ChatVertexAI,
    prefecture: str,
    main_title: str,
    sub_title: str,
    regional_chars: str,
) -> str:
    """ç”»åƒç”Ÿæˆç”¨ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆ"""
    try:
        prompt_input = IMAGE_PROMPT_TEMPLATE.format(
            prefecture=prefecture,
            main_title=main_title,
            sub_title=sub_title,
            regional_characteristics=regional_chars,
        )
        with st.spinner(
            "ç”»åƒç”Ÿæˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½œæˆä¸­... (ã“ã‚Œã¯UIã«ã¯è¡¨ç¤ºã•ã‚Œã¾ã›ã‚“)"
        ):  # ã‚¹ãƒ”ãƒŠãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’èª¿æ•´
            response = llm.invoke([HumanMessage(content=prompt_input)])
            generated_prompt = response.content.strip()
        if not generated_prompt:
            return f"Beautiful anime-style landscape of {prefecture}, Japan, featuring {regional_chars}, with theme of {sub_title}, 4:3 aspect ratio, high quality, detailed background art, no text, no characters"
        return generated_prompt
    except Exception as e:
        st.error(f"ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
        return f"Beautiful anime-style landscape of {prefecture}, Japan, featuring {regional_chars}, with theme of {sub_title}, 4:3 aspect ratio, high quality, detailed background art, no text, no characters"


def generate_image_with_model(
    image_model: ImageGenerationModel, prompt: str
) -> Optional[bytes]:
    """ç”»åƒç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã§ç”»åƒã‚’ç”Ÿæˆ"""
    try:
        negative_prompt = "text, words, letters, signs, logos, watermarks, signature, ugly, low quality, blurry, deformed, malformed, extra limbs, bad art, faces, people, characters, nsfw"
        with st.spinner("ç”»åƒã‚’ç”Ÿæˆä¸­... (å°‘ã—æ™‚é–“ãŒã‹ã‹ã‚Šã¾ã™)"):
            response = image_model.generate_images(
                prompt=prompt,
                number_of_images=1,
                aspect_ratio="4:3",
                negative_prompt=negative_prompt,
            )
        if response and response.images:
            image_obj = response.images[0]
            if hasattr(image_obj, "_image_bytes") and image_obj._image_bytes:
                return image_obj._image_bytes
            elif hasattr(image_obj, "image_bytes") and image_obj.image_bytes:
                return image_obj.image_bytes
            elif hasattr(image_obj, "_pil_image") and image_obj._pil_image:
                buffered = BytesIO()
                image_obj._pil_image.save(buffered, format="PNG")
                return buffered.getvalue()
        return None
    except Exception as e:
        st.error(f"ç”»åƒç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
        st.code(traceback.format_exc())
        return None


def image_to_base64(image_bytes: bytes) -> str:
    """ç”»åƒãƒã‚¤ãƒˆã‚’base64æ–‡å­—åˆ—ã«å¤‰æ›"""
    return base64.b64encode(image_bytes).decode("utf-8")


st.set_page_config(page_title="æ—¥æœ¬åœ°åŸŸç”»åƒç”Ÿæˆã‚¢ãƒ—ãƒª", layout="wide")
st.title("ğŸ—¾ æ—¥æœ¬åœ°åŸŸç‰¹æ€§ç”»åƒç”Ÿæˆã‚¢ãƒ—ãƒª")
st.markdown("é¸æŠã—ãŸéƒ½é“åºœçœŒã®ç‰¹æ€§ã‚’æ´»ã‹ã—ãŸç¾ã—ã„ã‚¢ãƒ‹ãƒ¡é¢¨ç”»åƒã‚’5æšç”Ÿæˆã—ã¾ã™ã€‚")

if not JAPAN_PREFECTURES:
    st.error("éƒ½é“åºœçœŒãƒªã‚¹ãƒˆã‚’èª­ã¿è¾¼ã‚ã¾ã›ã‚“ã€‚")
    st.stop()

image_model, llm = initialize_vertex_ai()

if not image_model or not llm:
    st.error("ãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
    st.stop()

with st.sidebar:
    st.header("âš™ï¸ è¨­å®š")
    selected_prefecture = st.selectbox("ğŸ“ éƒ½é“åºœçœŒã‚’é¸æŠ", JAPAN_PREFECTURES)
    regional_characteristics = ""
    if selected_prefecture:
        st.subheader(f"ğŸ“ {selected_prefecture} ã®ç‰¹æ€§")
        regional_characteristics = generate_regional_characteristics(
            llm, selected_prefecture
        )
        st.info(regional_characteristics)
    st.markdown("---")
    st.subheader("ğŸ“‹ ç”Ÿæˆçµæœç®¡ç†")
    if st.button("ğŸ—‘ï¸ ç”Ÿæˆç”»åƒã‚’ã‚¯ãƒªã‚¢"):
        if "article_images" in st.session_state:
            del st.session_state.article_images
            st.success("ç”Ÿæˆã•ã‚ŒãŸç”»åƒãƒ‡ãƒ¼ã‚¿ã‚’ã‚¯ãƒªã‚¢ã—ã¾ã—ãŸã€‚")
        else:
            st.info("ã‚¯ãƒªã‚¢ã™ã‚‹ç”»åƒãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        st.rerun()

st.subheader("ğŸ—¾ é¸æŠã•ã‚ŒãŸåœ°åŸŸ")
if selected_prefecture:
    st.info(f"**{selected_prefecture}**")
else:
    st.info("éƒ½é“åºœçœŒã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")

if st.button(
    "ğŸ¨ ç”»åƒç”Ÿæˆé–‹å§‹",
    type="primary",
    use_container_width=True,
    disabled=not selected_prefecture,
):
    if not selected_prefecture:
        st.warning("ã¾ãšéƒ½é“åºœçœŒã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
    else:
        progress_bar = st.progress(0, text="ãƒ†ãƒ¼ãƒç”Ÿæˆä¸­...")
        try:
            result = generate_titles_for_prefecture(selected_prefecture)
            titles_output = result.get("titles_output")
            if not titles_output:
                st.error("ãƒ†ãƒ¼ãƒç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
                st.stop()
            main_title = titles_output.get("main_title", "åœ°åŸŸã®ç¾")
            sub_titles_from_api = titles_output.get("sub_titles", ["ä¼çµ±çš„ãªé¢¨æ™¯"])
            progress_bar.progress(20, text="ãƒ†ãƒ¼ãƒç”Ÿæˆå®Œäº†")
        except Exception as e:
            st.error(f"ãƒ†ãƒ¼ãƒç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            st.code(traceback.format_exc())
            st.stop()

        num_target_images = 5
        final_sub_titles = list(sub_titles_from_api)
        if len(final_sub_titles) < num_target_images:
            for i in range(len(final_sub_titles), num_target_images):
                final_sub_titles.append(f"{main_title} - ç”Ÿæˆãƒ†ãƒ¼ãƒ {i + 1}")
        elif len(final_sub_titles) > num_target_images:
            final_sub_titles = final_sub_titles[:num_target_images]

        st.subheader("ğŸ“– ç”Ÿæˆã•ã‚ŒãŸãƒ†ãƒ¼ãƒ")
        st.markdown(f"**ãƒ¡ã‚¤ãƒ³ãƒ†ãƒ¼ãƒ:** {main_title}")
        st.markdown("**ã‚µãƒ–ãƒ†ãƒ¼ãƒ (ç”»åƒç”Ÿæˆã«ä½¿ç”¨):**")
        for i, subtitle in enumerate(final_sub_titles, 1):
            st.markdown(f"{i}. {subtitle}")

        st.markdown("---")
        st.subheader(f"ğŸ–¼ï¸ ç”Ÿæˆã•ã‚ŒãŸç”»åƒ ({selected_prefecture})")

        article_images_temp_list = []

        if "article_images" in st.session_state:
            del st.session_state.article_images

        cols = st.columns(num_target_images)

        for i, subtitle in enumerate(final_sub_titles):
            current_progress = 30 + (i * 70 // num_target_images)
            progress_bar.progress(
                current_progress,
                text=f"ç”»åƒ {i+1}/{num_target_images} ç”Ÿæˆä¸­ ('{subtitle}')...",
            )

            image_prompt = generate_image_prompt(
                llm, selected_prefecture, main_title, subtitle, regional_characteristics
            )

            image_bytes = generate_image_with_model(
                image_model,
                image_prompt,
            )

            if image_bytes:
                st.image(
                    image_bytes,
                    caption=f"{i+1}. {subtitle}",
                    use_container_width=True,
                )
                base64_data = image_to_base64(image_bytes)
                image_info = {
                    "src": f"data:image/png;base64,{base64_data}",
                    "alt": subtitle,
                }
                article_images_temp_list.append(image_info)
            else:
                st.error(f"ç”»åƒ {i+1} ('{subtitle}') ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚")

        progress_bar.progress(100, text="ç”»åƒç”Ÿæˆå®Œäº†!")

        st.session_state.article_images = article_images_temp_list  # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ä¸è¦

        if st.session_state.article_images:
            st.success(
                f"âœ… {len(st.session_state.article_images)} æšã®ç”»åƒã‚’ç”Ÿæˆã—ã€`st.session_state.article_images` ã«ä¿å­˜ã—ã¾ã—ãŸã€‚"
            )
            st.caption(
                "ã“ã‚Œã‚‰ã®ç”»åƒã¯ã€ä»–ã®ãƒšãƒ¼ã‚¸ã‚„ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®åˆ¥ç®‡æ‰€ã§å‚ç…§å¯èƒ½ã§ã™ã€‚"
            )
        else:  # article_images_temp_list ãŒç©ºã®å ´åˆï¼ˆã™ã¹ã¦ã®ç”»åƒç”Ÿæˆã«å¤±æ•—ï¼‰
            st.error("ç”»åƒã®ç”Ÿæˆã«ã™ã¹ã¦å¤±æ•—ã—ã¾ã—ãŸã€‚")

        if "article_images" in st.session_state and st.session_state.article_images:
            st.markdown("---")
            st.subheader("ğŸ–¼ï¸ ç¾åœ¨ã®ç”Ÿæˆç”»åƒãƒ‡ãƒ¼ã‚¿")
            st.caption(
                f"{len(st.session_state.article_images)} ä»¶ã®ç”»åƒãƒ‡ãƒ¼ã‚¿ãŒ `st.session_state` ã«ã‚ã‚Šã¾ã™ã€‚"
            )
            st.json(st.session_state.article_images)  # st.json ã§æ•´å½¢ã—ã¦è¡¨ç¤º
