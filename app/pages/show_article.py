from vertexai.generative_models import GenerativeModel
import streamlit as st
from config.config import get_config


def show_article():

    config = get_config()

    st.title("ğŸ’¬ Vertex AI ãƒãƒ£ãƒƒãƒˆã‚¢ãƒ—ãƒª")

    # --- ãƒãƒ£ãƒƒãƒˆã‚»ãƒƒã‚·ãƒ§ãƒ³ã®åˆæœŸåŒ– ---
    if "messages" not in st.session_state:
        st.session_state.messages = []

    if "chat_session" not in st.session_state:
        model = GenerativeModel(config["model_name"])
        st.session_state.chat_session = model.start_chat()

    # --- ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®è¡¨ç¤º ---
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    # --- ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã®å‡¦ç† ---
    if prompt := st.chat_input("ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„..."):
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        try:
            chat = st.session_state.chat_session
            response = chat.send_message(prompt)
            response_text = response.text

            st.session_state.messages.append(
                {"role": "assistant", "content": response_text}
            )
            with st.chat_message("assistant"):
                st.markdown(response_text)

        except Exception as e:
            st.error(f"Vertex AI ã¸ã®å•ã„åˆã‚ã›ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            st.warning("ã‚‚ã†ä¸€åº¦è©¦ã™ã‹ã€å°‘ã—å¾…ã£ã¦ã‹ã‚‰å†åº¦å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")

show_article()